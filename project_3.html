<!DOCTYPE HTML>
<!--
	Massively by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>Generic Page - Massively by HTML5 UP</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main.css" />
		<noscript><link rel="stylesheet" href="assets/css/noscript.css" /></noscript>
		<style>
			.small_table {
				margin-left: auto;
				margin-right: auto;
				width: 50%;
				text-align: center;
				border-bottom: 1px solid #ddd;
			}
			.item {
			  	margin: 5px auto;
			  	padding:10px;
			  	width: 50vw;
			}
			figure {
				text-align: center;
				font-style: italic;
<!--			  	border: 2px solid red;-->
			}
		</style>
	</head>
	<body class="is-preload">

		<!-- Wrapper -->
			<div id="wrapper">

				<!-- Header -->
					<header id="header">
						<a href="index.html" class="logo">Projects</a>
					</header>

				<!-- Nav -->
					<nav id="nav">
						<ul class="links">
							<li><a href="index.html">About</a></li>
							<li><a href="cv.html">CV</a></li>
							<li class="active"><a href="project_main.html">Projects</a></li>
						</ul>
						<ul class="icons">
							<li><a href="https://www.linkedin.com/in/won-sup-song-9015812a" class="icon brands fa-linkedin"><span class="label">Linkedin</span></a></li>
							<li><a href="https://github.com/wonsong94" class="icon brands fa-github"><span class="label">GitHub</span></a></li>
						</ul>
					</nav>

				<!-- Main -->
					<div id="main">
						<!-- Post -->
							<section class="post">
								<header class="major">
									<h1>Classification of Power Plants: CNN vs. General Regression Model</h1>
									<p>
										This article is a project from Machine Learning course: CS 229 at Stanford
										University. This project was aimed at exploring different machine learning
										frameworks and analyzing pros and cons of different models.
									</p>
								</header>
								<h2>Background</h2>
								<p>
									The energy sector is the second-largest consumer of water globally.
									In an era of growing concern around water risk, stakeholders are interested
									in quantifying water use by thermal power plants. In 2016 the World
									Resources Institute (WRI) created a new methodology that combines
									reported energy use data and power plant characteristics to generate estimates
									for water consumption by plant, and applied the methodology to over 85% (by
									installed capacity) of the Indian thermal energy sector.
									The methodology relied on individual inspection of power plants via
									satellite-based images. These inspections sought to classify power plants by
									cooling type, as different cooling types have significantly different visual
									features from satellite images, and the cooling types were used in turn to help
									characterize water consumption.
								</p>
								<figure>
								  <img class="item" src="images/page_3/Water_stress_2019_WRI.png" alt="" width="700">
								  <figcaption>Countries facing high water stress (Source from: WRI)</figcaption>
								</figure>
								<br/>
								<h3>Motivation</h3>
								<p>
									Visual inspection offers a reliable result of
									cooling type, but it is time-consuming. In order to generalize WRI’s methodology,
									the previously classified Indian plant data set can be used to build a machine
									learning model which can automatically classify plant cooling type and can be used
									for future uses if the results are reliable. In this project, we use different
									machine learning models to build a classifier that can predict the cooling types well.
								</p>
								<br/>
								<h2>Dataset & Features</h2>
								<p>
									We worked with a dataset of over 350 Indian power plants, which included multiple
									numerical and categorical labels such as: GPS location of the plant, presence or
									absence of each of the four cooling types, fuel type, installed capacity,
									plant capacity type, Indian State, Power Plant Parent Company, etc. (provided in a
									CSV file)These data were compiled both from visual inspection of satellite data
									and from existing commercial and public databases, made available by WRI.

									We manually confirmed the GPS locations for every
									power plant in our database, updating when appropriate and discarding if the
									location did not correspond to an actual power plant.
								</p>
								<figure>
									<img class="item" src="images/page_3/input_img.png" alt="" width="700">
									<figcaption>Characteristics of Dry, Mechanical Draft, Natural Draft, and Once-through (from left to right)</figcaption>
								</figure>
								<br/>
								From visual inspection, the following are the key image features that characterize
								type of plants:
								<ul>
									<li>Dry: rectangular tile on black</li>
									<li>Mechanical Draft: aligned circular plates</li>
									<li>Once-Through: existence of artificial dam (river near power plant)</li>
									<li>Natural Draft: cooling tower towering in a chimney shape</li>
								</ul>
								<br/>
								<h2>Problem Forumlation</h2>
								<p>
									We used two separate models to test the prediction model: <b>Binomial Logistic Regression </b>and
									<b>ConvNet based on transfer learning with the MobileNet model</b>. For both our
									logistic regression and neural net, <u>we chose to use four binomial
									models to predict our four cooling types, rather than using a single multinomial
									model.</u> We chose four binomial models because some power plants use two different
									cooling types rather than a single cooling type, which makes it a multi-label classification
									problem, reducing the model accuracy to classify each plant or image of a plant
									as containing strictly one cooling type.
								</p>
								<br/>
								<h2>Model 1: Binomial logistic regression</h2>
								The logistic regression models use numerical and categorical
								features other than GPS locations, such as:
								<ul>
									<li>fuel type</li>
									<li>installed thermal capacity</li>
									<li>Plant Capacity Factor (PCF)</li>
									<li>etc.</li>
								</ul>
								<p>
									To build a training model that best predicts the plant's cooling type, we used
									one-vs-one method for binary classification and used k-fold cross validation to
									randomly sample from the dataset to select the best set of data
									that has less bias than others. In our binomial logistic regression model, we used the
									following configuration:
								</p>
								<table class="small_table">
									<tr>
										<th>Training Set</th>
										<th>n = 230</th>
									</tr>
									<tr>
										<th>Test Set</th>
										<th>n = 80</th>
									</tr>
									<tr>
										<th>k-fold Cross Validation</th>
										<th>k = 10</th>
									</tr>
									<tr>
										<th>Number of Iterations</th>
										<th>Iteration = 30</th>
									</tr>
								</table>

								<p>
									For each of our four binomial outputs (cooling type), we
									performed 30 iterations of 10-fold cross validation on various models. Multiple
									cross validations were conducted to obtain the best dataset that captures the
									characteristic of the model that best predicts the cooling type.
									We used a simple function which returned 1 for a correct prediction and 0 for an incorrect
									prediction, averaged over all predictions (Equation 2). After selecting the four
									models with the best 10-fold cross validation accuracy, we
									predicted on the test set and reported the accuracy.
								</p>
								<p>
									Our logistic regression model used python sklearn.multiclass package OneVsOneClassifier.
									which takes in labeled dataset so that sigmoid function is applied to a
									linear combination of the features to generate a number between 0 and 1.
									The sigmoid output is treated as a probability as shown in the following equation.
									When it is greater than 0.5, we predict the presence of the modeled cooling type,
									and when it is less than 0.5 we predict its absence.
								</p>
								<figure>
									<img src="images/page_3/logistic_equation.png" alt="" width="25%">
								</figure>
								<p>
									To measure accuracy, we used a simple function which returned 1 for a correct
									prediction and 0 for an incorrect prediction, averaged over all predictions
									as shown in equation below. After selecting the four models with the best 10-fold cross
									validation accuracy, we predicted on the test set to test the accuracy.
								</p>
								<figure>
									<img src="images/page_3/logistic_equation_2.png" alt="" width="20%">
								</figure>
								<br/>
								<h3>Classification Results</h3>
								<p>
									Results from our logistic regression model are presented in Table 1 below.
									Results for dry cooling in particular, as well as natural draft and once-through
									are promising. Almost 20% of our data have missing GPS coordinates, so our ability
									to predict cooling type based on other available features is an important
									contribution to data imputation for this class of problem. Mechanical draft
									prediction underperforms other categories--we believe the other parameters simply
									do not contain sufficient information to predict mechanical draft cooling with
									high accuracy.
								</p>
								<table>
									<tr>
										<th></th>
										<th>Mechanical Draft</th>
										<th>Natural Draft</th>
										<th>Dry</th>
										<th>Once-Through</th>
									</tr>
									<tr>
										<th>Cross Validation Accuracy</th>
										<th>65%</th>
										<th>82%</th>
										<th>86%</th>
										<th>94%</th>
									</tr>
									<tr>
										<th>Test Accuracy</th>
										<th>71.25%</th>
										<th>78.75%</th>
										<th>88.75%</th>
										<th>82.50%</th>
									</tr>
								</table>

								<br/>
								<h2>Model 2: Image classification using MobileNet architecture</h2>
								<p>
									Our second model uses the general architecture of MobileNets, a streamlined
									CNN architecture that uses depth-wise separable convolutions to build light-weight
									deep neural networks. We selected MobileNet for its relative speed and simplicity,
									which allowed us both to rapidly prototype and iterate, and was appropriate given
									our small volume of data. Also, as many ConvNets are parameter-rich and pront to
									overfitting, we selected a simpler ConvNet with a smaller parameter space.
								</p>
								<figure>
									<img class="item" src="images/page_3/mobile_net.png" alt="" width="700">
									<figcaption>Schematic of MobileNet Architecture</figcaption>
								</figure>
								<br/>
								<p>
									We managed the entire retraining process via Tensorflow’s recommended retrain.py
									script, which also features easy methods to control gradient descent batch size,
									train/dev/test size, and certain distortions.

									Finally, in our implementation of the MobileNet model, the weights for every
									layer were maintained except for the last fully-connected layer to retrain this layer
									on our images.
								</p>
								<br/>
								<h3>Data Augmentation by image distortions</h3>
								<p>
									Image distortions act in a manner similar to
									regularization, forcing the ConvNet to generalize rather than simply “memorizing”
									the training set. This technique is used extensively in image classification
									in order to overcome small number of datasets and overfitting. We can take advantage
									of this technique to overcome overfitting problem due to
									our small number of datasets (n = 350). We do this by varying the following:
								</p>
								<ul>
									<li>image offsets</li>
									<li>size scaling</li>
									<li>brightness</li>
									<li>orientation (left/right switching)</li>
								</ul>
								<p>
									The application of distortions increased our computational time
									by several orders of magnitude, and had little effect at low levels, but with 80%
									random offsets, random scaling, and random brightness in addition to random
									left/right switching we were able to bring our dev set accuracy up to almost 70%.
								</p>

								<br/>
								<h3>Classification Results</h3>
								<p>
									Results from our ConvNet are presented in Table 2. Training and development set
									numbers reflect the values to which the training and development set accuracies
									converged. Results for natural draft, dry, and once-through cooling types surpassed
									results from our logistic regression model (after correct pre-processing was applied).
								</p>
								<table>
									<tr>
										<th></th>
										<th>Mechanical Draft</th>
										<th>Natural Draft</th>
										<th>Dry</th>
										<th>Once-Through</th>
									</tr>
									<tr>
										<th>Training Accuracy</th>
										<th>100%</th>
										<th>100%</th>
										<th>100%</th>
										<th>100%</th>
									</tr>
									<tr>
										<th>Test Accuracy (N = 84)</th>
										<th>68.8%</th>
										<th>98.9%</th>
										<th>62.5%</th>
										<th>61.4%</th>
									</tr>
								</table>
								<p>
									We found that the results for mechanical draft cooling are disappointing,
									as humans can identify mechanical draft cooling structures with high (>95%) accuracy.
									As it can be seen from Figure 2, our mechanical draft model suffers badly from overfitting.
								</p>
								<figure>
								  <img class="item" src="images/page_3/result.png" alt="" width="700">
								  <figcaption>Training (orange) and dev (blue) accuracy as a function of iterations for Mechanical Draft</figcaption>
								</figure>
								<p>
									Our original dev set accuracies were as low as 55% while training set accuracies converged to
									100%. To solve this overfitting problem we tried a number of steps, including
									simpler model selection and random image distortions applied to training samples
									before each batch iteration.
								</p>

								<br/>
								<h3>Potential factors in misclassification</h3>
								<figure>
								  <img class="item" src="images/page_3/misrepresented.png" alt="" width="700">
								  <figcaption>Potential factors in misclassification</figcaption>
								</figure>

								<br/>
								<p>
									It could be seen that:
								</p>
								<ul>
									<li>Existence of Water for Natural Drafts: Natural Draft that has rivers and oceans nearby could be misclassified as once-through</li>
									<li>No Observed Plants: If the power plant is missing or far from the given coordinates</li>
									<li>Existence of Smoke: Circular plate characteristic of Mechanical Draft is not visible</li>
									<li>Transition Boundary: When satellite images are taken at different times, different tones are created</li>
								</ul>

								<br/>
								<h2>Discussion on model performance</h2>
								<p>
									The ConvNet uses a satellite image of the power plant as input to predict plant
									cooling type, as each cooling type is associated with specific visual
									characteristics. Our ConvNet is more accurate, but requires the
									plant’s GPS location. Even our own data contains many instances where GPS data is
									missing or inaccurate--under these conditions, our logistic regression model
									generates a useful estimate for cooling type.
								</p>
								<p>
									Unfortunately, we were unable to apply conventional regularization, as MobileNets
									is explicitly designed with minimal regularization (due to its already small
									parameter space) and our workflow did not allow a simple method to directly modify
									our weights’ update rules. Note the stochasticity of our accuracy in
									Figure 2--despite greatly reducing the learning rate, we were unable to find a
									smooth learning rate that did not require an infeasible number of iterations to
									convergence.
								</p>
								<br/>
								<h2>Conclusion / General comments</h2>
								<p>
									Our two models offer successful methods for classifying cooling types under a
									variety of conditions. When GPS coordinates are not available, our logistic
									regression model offers an acceptable “best guess” given there is no current
									human-driven methodology to estimate cooling types from other features. When GPS
									coordinates are available, our ConvNet offers classification on par with human
									classification for 3 of the 4 plant cooling types. Future opportunities include
									deeper changes to the MobileNets architecture in order to address the variance
									problem for mechanical draft prediction (e.g. the addition of L2 regularization).
							</section>
					</div>

				<!-- Copyright -->
					<div id="copyright">
						<ul><li>Won Sup Song</li><li>Design: <a href="https://html5up.net">HTML5 UP</a></li></ul>
					</div>

			</div>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/jquery.scrollex.min.js"></script>
			<script src="assets/js/jquery.scrolly.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>

	</body>
</html>